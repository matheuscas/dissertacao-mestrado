\documentclass[template.tex]{subfiles}
\begin{document}

\xchapter{Resultados obtidos}{}

Nessa seção são descritos e discutidos os experimentos realizados e os resultados obtidos desses experimentos. O objetivo principal não é comparar qual cenário obtém melhor \textit{acuracia} ou TPR e TNR, mas também discutir em quais contextos os classificadores produzem melhores ou piores resultados.

\section{Datasets}
\todo[inline]{Pelo que vi nos comentários da seção de metodologia essa seção deve sumir daqui e subir para para metodologia, certo?}

Nós executamos nossos experimentos em três bases de dados. Duas já foram mencionadas anteriormente, que são a base de dados de filmes \cite{pang2004sentimental} e a de diferentes categorias da Amazon \cite{wang2011latent}. Ambas contém 2000 documentos que foram previamente classificadas pelo sentimento geral das opiniões como sendo positivos ou negativos. Além disso, estas bases são ditas equilibradas, pois tem a mesma quantidade de documentos positivos e negativos. 

Para a base da Amazon, a referência para definir o sentimento geral dos documentos foi a quantidade de estrelas recebidas pelo usuário: mais de três estrelas o documentos era considerado positivo e menos que isso, negativo. Os documentos com exatamente 3 estrelas foram removidos de nossa análise por não serem claros quanto ao sentimento geral expresso para serem usados como referência. Além disso, a base da Amazon, originalmente, possui 20000 documentos. Contudo ela está  desbalanceada, onde mais 75\% dos documentos são positivos e o restante negativos. Assim, sorteamos, aleatoriamente, 1000 documentos positivos e 1000 documentos negativos para equiparar ao mesmo volume de dados da base de filmes. Sobre a base de filmes, como já dissemos anteriormente, esta já tinha sido pré classificada por seus autores \cite{pang2004sentimental}.

A terceira base, um conjunto de documentos retirados do site Epinions por \cite{taboada2011lexicon}, é composta por 400 documentos de 8 categorias diferentes: livros, carros, computadores, panelas, hotéis, filmes, música e telefones. Cada categoria possui 50 documentos equilibrados, sendo 25 positivos e 25 negativos, classificados préviamente pelo autor da base. Essa base foi utilizada para verificarmos a efetividade de regras criadas em uma base de dados e usadas em outras, nesse caso, a base da Epinions. 

\section{Design dos experimentos}

Nós focamos em comparar os métodos de classificação MRFG e MRFC, variando as configurações em diferentes etapas do processo de mineração de opinião, comparando \textit{acuracia}, TPR e TNR. Nós também avaliamos a influência dos algoritmos de seleção de características, os sistemas de inferência fuzzy em si, a quantidade usada de conjuntos fuzzy, a eficiência das regras entre domínios e usadas em outro e as características mais selecionadas entre as bases utilizadas. 

Para cada base de dados, o processo de mineração de opinião é idêntico para as etapas de pré-processamento, transformação e extração de características. A partir da seleção de características, as etapas seguintes foram executadas com validação cruzada de 10 dobras, utilizando somente as treinamento. Por exemplo, a dobra 1 não é usada para a seleção de características, pois é usada como teste nas etapas seguintes de classificação e avaliação. As dobras restantes são usadas na seleção de características e na construção da base de regras fuzzy para aquela dobra de teste 1. O mesmo processo é repetido para cada dobra e os resultados, para todas as métricas usadas, são a média dos valores obtidos nas dobras de teste. 
%Conseqüentemente, todos os tipos de n-grams combinados com todas as técnicas de transformação descritas nesse trabalho passam pela seleção de características para encontrar quais delas são mais apropriadas para representar os documentos. 

\subsection{Avaliação dos algoritmos de seleção de características}

Para avaliar os algoritmos de seleção de características, CFS e C45, foi definido o seguinte cenário: 3 conjuntos fuzzy para as variáveis de entrada e o uso do MRFC para ambas bases de dados, filmes e a base mista da Amazon. Assim, deixando os demais parâmetros inalterados, nós podemos avaliar o desempenho dos algoritmos de seleção de características. Além de avaliar \textit{acuracia}, TPR e TNR, foi avaliado também a quantidade média de características selecionadas para cada algoritmo de seleção. A tabela (\ref{table:movies}) e tabela (\ref{table:amazon}) mostram, respectivamente, os resultados para este cenário nas bases de filmes e da Amazon. 

\begin{table}[!h]
    \begin{tabular}{lll}
    Movies         				 				& CFS                                 	 	& c4.5                                  \\ \hline
    TNR                   						& 40.3\% $\pm$ 6.09\% 			 	& 47.1\% $\pm$ 42.67\% \\
    TPR                        					& 64.2\% $\pm$ 30.55\% 		    & 61.7\% $\pm$ 43.93\% \\
    acuracia                   				& 52.25\% $\pm$ 4.92\% 			 & 54.4\% $\pm$ 1.72\% \\
    Características selecionadas & 4.7 $\pm$ 1.1            			 	 & 1                                     \\
    \end{tabular}
    \caption{Resultados da base de filmes}
	\label{table:movies}
\end{table}

%SVM Filmes

%---> Avg TPR:  69.1 %
%Standard Deviation:  7.3 %
%---> Avg TNR:  72.1 %
%Standard Deviation:  6.87677249878 %
%---> Avg acuracia:  70.6 %
%Standard Deviation:  3.44818792991 %

%WILCOXON
%two-tailed

%Result 1 - Z-value
%The Z-value is -1.1212. The p-value is 0.26272. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%The W-value is 16.5. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

\begin{table}[!h]
    \begin{tabular}{lll}
    Movies         										& CFS                          		& c4.5                                  \\ \hline
    TNR                     								& 51.3\% $\pm$ 13.56\% 	& 34.0\% $\pm$ 43.26\%  \\
    TPR                          						& 77.5\% $\pm$ 13.9\% 		& 74.5\% $\pm$ 38.82\% \\
    acuracia                     					& 64.4\% $\pm$ 8.12\% 		& 54.25\% $\pm$ 2.82\% \\\
    Características selecionadas 		& 5.3 $\pm$ 0.64               & 1 $\pm$                                  \\
    \end{tabular}
    \caption{Resultados da base da Amazon}
	\label{table:amazon}
\end{table}

%SVM
%
%---> Avg TPR:  65.8 %
%Standard Deviation:  4.6432747065 %
%---> Avg TNR:  75.5 %
%Standard Deviation:  3.20156211872 %
%---> Avg acuracia:  70.65 %
%Standard Deviation:  2.99207286008 %

%WILCOSOX
%
%Result 1 - Z-value
%The Z-value is -2.3953. The p-value is 0.0164. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%The W-value is 4. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

Em ambas as bases as diferenças entre os resultados não são significativas usando o teste \textit{Wilcoxon signed-rank} para $p <= 0.01$. Isso mostra que mesmo que o CFS utiliza quase 5 vezes mais características em ambas as bases e não consegue produzir resultados significativamente melhores, criando ainda regras mais complexas e de difícil compreensão para seres humanos. Assim, já que o algoritmo c4.5 somente precisou de 2 características, produzindo regras menos complexas e mais claras, para produzir resultados próximos ou iguais ao do CFS, decidiu-se em manter o c4.5 para os próximos cenários de avaliação. 

Um outro comportamento comum para ambas as bases foi expressivo desvio padrão de cada medida. Foi possível perceber que a em cada dobra da validação cruzada, documentos positivos eram classificados mais corretamente em detrimento aos negativos e vice-versa. A tabela (\ref{table:amazon_folds}) mostra as matrizes de confusão de cada dobra para os resultados produzidos na base da Amazon. 

\begin{table}[!h]
    \begin{tabular}{lll}
    a         					& b                          		& classificado como                                  \\ \hline
	Dobra 0 \\    
    100 (TP)    				&0 (FN)      				& a = positivo(100) \\
    92 (FP)    				&8 (TN)      				& b = negativo (100) \\
	&&\\
	Dobra 1    \\
    22 (TP)    				&78 (FN)      				& a = positivo(100) \\
    0 (FP)    				&100 (TN)      			& b = negativo (100) \\   
	&&\\ 
	Dobra 2    \\
    100 (TP)    				&0 (FN)      				& a = positivo(100) \\
    95 (FP)    				&5 (TN)      				& b = negativo (100) \\   
	&&\\
    Dobra 3    \\
    100 (TP)    				&0 (FN)      				& a = positivo(100) \\
    95 (FP)    				&5 (TN)      				& b = negativo (100) \\   
	&&\\
	Dobra 4    \\
    12 (TP)    				&88 (FN)      				& a = positivo(100) \\ 
    0 (FP)    				&100 (TN)      				& b = negativo (100) \\
	&&\\
	Dobra 5    \\
    99 (TP)    				&1 (FN)      				& a = positivo(100) \\ 
    96 (FP)    				&4 (TN)      				& b = negativo (100) \\
	&&\\
	Dobra 6    \\
    100 (TP)    				&0 (FN)      				& a = positivo(100) \\ 
    99 (FP)    				&1 (TN)      			& b = negativo (100) \\
	&&\\
	Dobra 7    \\
    12 (TP)    				&88 (FN)      				& a = positivo(100) \\ 
    0 (FP)    				&100 (TN)      				& b = negativo (100) \\
	&&\\
	Dobra 8    \\
    100 (TP)    				&0 (FN)      				& a = positivo(100) \\ 
    92 (FP)    				&8 (TN)      				& b = negativo (100) \\
	&&\\
	Dobra 9    \\
    100 (TP)    				&0 (FN)      				& a = positivo(100) \\ 
    91 (FP)    				&9 (TN)      				& b = negativo (100) \\
	&&\\
    \end{tabular}
    \caption{Resultados das dobras da base da Amazon}
	\label{table:amazon_folds}
\end{table}

É possível perceber que há alternância entre as dobras para as extremidades da classificação dos documentos: ou são todos (ou quase) positivos ou quase todos negativos. E ainda que um novo embaralhamento dos dados seja feito e uma nova seleção de características, o efeito se repete e os resultados também. 

\subsubsection{Avaliação do impacto da altura da árvore de decisão do algoritmo de seleção de características do c4.5}

É importante ressaltar que os resultados anteriores, para o c4.5, foram obtidos com o algoritmo otimizado, utilizando a ferramenta Weka [CITE], para que a árvore do algoritmo de seleção de características do algoritmo tivesse altura 1, para fins de simplificação das regras geradas. Dessa forma, decidimos avaliar o quanto o aumento da altura da árvore de decisão do algoritmo de seleção de características do c4.5 influenciaria na classificação dos documentos. Definimos que o limite da altura da árvore de decisão fosse 3 para não aumentar demais a complexidade das regras que seriam geradas. A tabela (\ref{table:movies_h3}) e tabela (\ref{table:amazon_h3}) mostram, respectivamente, os resultados para este cenário nas bases de filmes e da Amazon.

 \begin{table}[!h]
    \begin{tabular}{lll}
    Movies         				 					  & c4.5 - Altura 3                                 	 	 & c4.5 - Altura 1                               \\ \hline
    TNR                   					  		  & 55.6\% $\pm$ 43.49\% 			 				& 47.1\% $\pm$ 42.67\% \\
    TPR                        					  	  & 53.4\% $\pm$ 44.50\% 		 					& 61.7\% $\pm$ 43.93\% \\
    acuracia                   					  & 54.5\% $\pm$ 1.76\% 			 				& 54.4\% $\pm$ 1.72\% \\
    Características selecionadas      & 1.1 $\pm$ 0.3            			 					& 1                                     \\
    \end{tabular}
    \caption{Resultados da base de filmes}
	\label{table:movies_h3}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -1.7838. The p-value is 0.07508. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 10. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

\begin{table}[!h]
    \begin{tabular}{lll}
    Movies         										& c4.5 - Altura 3                          		& c4.5 - Altura 1                              \\ \hline
    TNR                     								& 73.7\% $\pm$ 35.86\% 					& 34.0\% $\pm$ 43.26\%  \\
    TPR                          						& 47.1\% $\pm$ 34.22\% 					& 74.5\% $\pm$ 38.82\% \\
    acuracia                     					& 60.4\% $\pm$ 5.75\% 						& 54.25\% $\pm$ 2.82\% \\
    Características selecionadas 		& 1.9 $\pm$ 0.7               					& 1 $\pm$                                  \\
    \end{tabular}
    \caption{Resultados da base da Amazon}
	\label{table:amazon_h3}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -2.1915. The p-value is 0.02852. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 6. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

Mais uma vez, os resultados apresentados em ambas as bases para o aumento da altura da árvore de decisão do algoritmo de seleção de características não produziram resultados significativamente melhores para $p <= 0.01$ no teste \textit{Wilcoxon signed-rank}. Assim, o crescimento da árvore, que resulta no aumento da complexidade das regras em relação a altura 1, não contribui para o aumento de performance do nosso classificador e na simplificação das regras geradas para a classificação. 

\subsection{Avaliação dos sistemas de inferência}

Nessa subseção é avaliado o desempenho dos sistemas de inferência escolhidos, o Método Geral do Raciocínio Fuzzy (MRFG) e o Método Clássico do Raciocínio Fuzzy (MRFC). Da mesma maneira que foi feita na seção anterior, nós fixamos os demais parâmetros do experimento para melhor avaliar os sistemas de inferência, mantendo o algoritmo de seleção de característica c4.5 (com altura 1, para continuar buscando a geração de regras claras e de fácil leitura para humanos) e 3 conjuntos fuzzy nas variáveis de entrada. A tabela (\ref{table:movies2}) e tabela (\ref{table:amazon2}) mostram, respectivamente, os resultados para este cenário nas bases de filmes e da Amazon.

\begin{table}[!h]
    \begin{tabular}{lll}
 	~         			& CFRM 								& GFRM \\ \hline
    TNR 				& 47.1\% $\pm$ 42.67\%   & 53.8\% $\pm$ 34.96\%    \\
    TPR    			& 61.7\% $\pm$ 43.93\%   & 64.6\% $\pm$ 37.08\%   \\
    acuracia  		& 54.4\% $\pm$ 1.72\%    	& 59.2\% $\pm$ 1.83\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base de filmes}
	\label{table:movies2}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -2.8031. The p-value is 0.00512. The result is significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 0. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is significant at p≤ 0.01.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& CFRM 									& GFRM \\ \hline
    TNR 				& 34.0\% $\pm$ 43.26\%    	& 44.6\% $\pm$ 35.73\%    \\
    TPR    			& 74.5\% $\pm$ 38.82\%    	& 75.5\% $\pm$ 34.80\%    \\
    acuracia  		& 54.25\% $\pm$ 2.82\%    	& 60.05\% $\pm$ 2.37\%   \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base da Amazon}
	\label{table:amazon2}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -2.8031. The p-value is 0.00512. The result is significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 0. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is significant at p≤ 0.01.

Os resultados mostram que Método Geral do Raciocínio Fuzzy (MRFG) aumenta o \textit{acuracia} sobre o MRFC, em ambas bases,  mantendo a seleção de características e a quantidade de conjuntos fuzzy inalterados. O resultado do teste \textit{Wilcoxon signed-rank} confirma a melhora significativa do MRFG sobre o MRFC, para $p <= 0.01$. Assim, nessa tarefa de classificação de somente duas classes, positivo e negativo, os resultados mostraram que uma melhor abordagem é considerar todas as regras de uma classe, em vez de uma única com maior grau. Daí, o MRFG foi a nossa escolha para prosseguir nos próximos experimentos com o fim de alcançar melhores resultados nesse trabalho.

\subsection{Avaliação de uso de pesos nas regras dos sistemas de inferência}

Em \cite{ishibuchi2001effect} foi mostrado que é possível aumentar a performance da classificação de regras fuzzy IF-THEN, aplicando pesos à elas, além do grau de compatibilidade das regras. No referido artigo, os autores descreveram o processo em que é possível melhorar o desempenho da classificação sem alterar os conjuntos fuzzy das variáveis de saída e de entrada. Baseando-se neste artigo, este trabalho calculou os pesos como se segue. Para cada regra da base de regras gerada, foi calculado o grau de compatibilidade com todos documentos do conjunto de teste. Se o documento fosse positivo, o grau de compatibilidade era acumulado em $\beta_{positivo}$; se o documento fosse negativo, o grau de compatibilidade era acumulado em $\beta_{negativo}$. Ao fim desse processo, caso ambos os betas fosse iguais, não haveria peso a ser considerado, já que as regras tem igual influência sobre o conjunto de dados que elas foram geradas. De outra forma, o peso da regra era definido pela equação \ref{eq:pesos}.

\begin{equation}
P_j = |\beta_{positivo} - \beta_{negativo}| / (\beta_{positivo} + \beta_{negativo})
\label{eq:pesos}
\end{equation}

onde $P_j$ é o peso da regra, para $0 <= P_j <= 1$. 

Uma vez que todas as regras tiveram seus pesos calculados, estes são adicionados ao processo de classificação de ambos os métodos utilizados até aqui, o MRFG e o MRFC. O peso torna-se um fator multiplicador do grau de cada regra. Assim, o MRFC em vez de somente levar em consideração a regra com maior grau de compatibilidade com o documento de teste, vai, agora, levar em consideração a regra com maior grau multiplicado pelo peso da regra. O mesmo acontece para o MRFG ao considerar o grau médio entre as classes positivo e negativo. A tabela (\ref{table:movies2_pesos}) e tabela (\ref{table:amazon2_pesos}) mostram, respectivamente, os resultados para o uso dos pesos nas bases de filmes e da Amazon usando os parâmetros até agora estabelecidos. 

\begin{table}[!h]
    \begin{tabular}{lll}
 	~         			& S/ Pesos 								& C/ Pesos \\ \hline
    TNR 				& 53.8\% $\pm$ 34.96\%   	& 70.4\% $\pm$ 7.11\%    \\
    TPR    			& 64.6\% $\pm$ 37.08\%   	& 69.7\% $\pm$ 9.81\%   \\   
    acuracia  		& 59.2\% $\pm$ 1.83\%    	& 70.05\% $\pm$ 4.00\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base de filmes utilizando pesos nas regras}
	\label{table:movies2_pesos}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -2.8031. The p-value is 0.00512. The result is significant at p≤ 0.05.
%
%Result 2 - W-value
%
%The W-value is 0. The critical value of W for N = 10 at p≤ 0.05 is 8. Therefore, the result is significant at p≤ 0.05.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& S/ Pesos									& C / Pesos \\ \hline
    TNR 				& 44.6\% $\pm$ 35.73\%    	& 76.80\% $\pm$ 4.57\%    \\
    TPR    			& 75.5\% $\pm$ 34.80\%    	& 64.9\% $\pm$ 5.50\%    \\
    acuracia  		& 60.05\% $\pm$ 2.37\%    	& 70.85\% $\pm$ 3.09\%   \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base da Amazon utilizando pesos nas regras}
	\label{table:amazon2_pesos}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -2.8031. The p-value is 0.00512. The result is significant at p≤ 0.05.
%
%Result 2 - W-value
%
%The W-value is 0. The critical value of W for N = 10 at p≤ 0.05 is 8. Therefore, the result is significant at p≤ 0.05.

Os resultados corroboraram as conclusões de \cite{ishibuchi2001effect} que é possível melhorar o desempenho da classificação sem alterar os conjuntos fuzzy das variáveis de saída e de entrada apenas aplicando pesos às regras geradas. O resultado do teste \textit{Wilcoxon signed-rank} também confirma a melhora significativa do MRFG usando pesos nas regras em vez de somente o grau de compatibilidade, para $p <= 0.01$.

\subsection{Avaliação da quantidade de conjuntos fuzzy usados}

Através das últimas seções, foram mostrados resultados utilizando 3 conjuntos fuzzy para modelar nossas variáveis lingüísticas. Seguindo a nossa decisão de usar o c4.5 com altura máxima da árvore de decisão para 1 para reduzir a complexidade das regras geradas e torna-las mais legíveis para seres humanos, nós tentamos reduzir a quantidade de conjuntos fuzzy, usando somente os conjuntos "Baixo" e "Alto", para as variáveis de entrada. Esse experimento tem por fim verificar se há aumento da performance da classificação com regras mais simples e gerais. A tabela (\ref{table:movies2_pesos_2f}) e tabela (\ref{table:amazon2_pesos_2fs}) mostram, respectivamente, os resultados para o uso de somente dois conjuntos fuzzy nas variáveis de entrada nas bases de filmes e da Amazon.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& 3 conjuntos fuzzy 							& 2 conjuntos fuzzy \\ \hline
    TNR 		  		& 70.4\% $\pm$ 7.11\%         			& 71.2\% $\pm$ 4.33\%    \\
    TPR    		 	& 69.7\% $\pm$ 9.81\%        			& 70.6\% $\pm$ 3.35\%   \\
    acuracia  	 	& 70.05\% $\pm$ 4.00\%    			& 70.9\% $\pm$ 3.07\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base de filmes utilizando 2 conjuntos fuzzy na entrada}
	\label{table:movies2_pesos_2fs}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -1.2741. The p-value is 0.20408. The result is not significant at p≤ 0.05.
%
%Result 2 - W-value
%
%The W-value is 15. The critical value of W for N = 10 at p≤ 0.05 is 8. Therefore, the result is not significant at p≤ 0.05.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& 3 conjuntos fuzzy 							& 2 conjuntos fuzzy \\ \hline
    TNR 				& 76.80\% $\pm$ 4.57\%            	& 77.2\% $\pm$ 3.54\%    \\
    TPR    			& 64.9\% $\pm$ 5.50\% 					& 64.4\% $\pm$ 3.46\%   \\
    acuracia  		& 70.85\% $\pm$ 3.09\%         		& 70.8\% $\pm$ 3.27\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base da Amazon utilizando 2 conjuntos fuzzy na entrada}
	\label{table:amazon2_pesos_2fs}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -0.3568. The p-value is 0.71884. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 24. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

A tabela (\ref{table:movies2_pesos_2fs}) mostra pequena melhora na base de filmes e empate técnico na base da Amazon. Mas, estatisticamente, os resultados não são significativamente diferentes para $p <= 1$. Todavia, a redução da quantidade dos conjuntos fuzzy para as variáveis de entrada produz regras mais simples e legíveis para serem humanos. Assim, nós temos regras menos complexas com a mesma performance de regras com maior número de antecedentes. 

%positive_to_negative_ratio_of_adjectives_sum_and_bigrams_with_adjectives
%positive_to_negative_ratio_of_unigrams_and_bigrams_sum
Em ambos conjuntos de dados somente duas características foram selecionadas pelo c4.5:
\begin{itemize}
\item Diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo
\item Diferença entre a soma positiva e negativa dos unigrams e bigrams
\end{itemize}

Na base de filmes as duas foram necessárias para atingir os resultados mostrados na tabela ((\ref{table:movies2_pesos_2fs})). Isso remete ao fato de documentos de filmes serem mais difíceis de ser classificados, precisando de mais características para caracterizar corretamente as opiniões \cite{turney2002thumbs, pang2004sentimental, chaovalit2005movie, ohana2009sentiment}. Já na base da Amazon, somente a segunda característica foi utilizada para classificar os documentos. Embora o algoritmo de seleção de características do c4.5 tenha decidido que somente essa característica seja suficiente, não é difícil concluir que, sendo a base da Amazon bastante diversa (e que também inclui filmes), mais características podem ser necessárias para caracterizar melhor documentos tão variados.
Todavia, nós conseguimos classificar um pouco mais de 70\% dos documentos de filmes e da Amazon com poucas regras simples, legíveis para humanos, geradas pelo método de Wang-Mendel:

\begin{itemize}
\item IF a \textit{diferença entre a soma positiva e negativa dos unigrams e bigrams} is ALTO then POLARIDADE is POSITIVA
\item IF a \textit{diferença entre a soma positiva e negativa dos unigrams e bigrams} is BAIXO then POLARIDADE is NEGATIVA
\item IF a \textit{diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo} is ALTO then POLARIDADE is POSITIVA
\item IF a \textit{diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo} is BAIXO then POLARIDADE is NEGATIVA
\end{itemize}

As quatro regras foram utilizadas na base de filmes e as duas primeiras regras na base da Amazon.

\subsection{Avaliação do uso de regras entre domínios}

Outra avaliação que fizemos foi a validação do uso de regras entre domínios, utilizando a base inteira da Epinions como teste. Foram usadas as regras geradas da base de filmes e da base da Amazon e aplicadas à base da Epinions. Para isso, a base da Epinions passou por pré-processamento, transformação e extração de características, para que as regras pudessem avaliar corretamente os documentos. É importante frisar que nenhuma adaptação foi feita às regras para que pudesse funcionar corretamente. Da maneira que foram geradas na bases de filmes e Amazon, foram utilizadas na classificação dos documentos da base da Epinions. A tabela \ref{table:epinions} mostra os resultados obtidos.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         		& Regras da Amazon 					& Regras dos Filmes \\ \hline
    TNR 			& 47.05\% $\pm$ 0.35\%           & 61.7\% $\pm$ 1.41\%    \\
    TPR    		& 90.5\% $\pm$ 1.11\% 				& 85.8\% $\pm$ 1.22\%   \\
    acuracia  	& 68.77\% $\pm$ .0.17\%         	& 73.75\% $\pm$ 0.27\%    \\
    \end{tabular}
    \caption{Resultados da aplicação de regras da base de filmes e Amazon na base Epinions}
	\label{table:epinions}
\end{table}

Os resultados mostram que as regras geradas podem ser usadas entre domínios diferentes, produzindo resultados próximos ou melhores que os produzidos nas próprias bases, como pode ser visto na tabela \ref{table:epinions}.

\subsection{Outros resultados}

Cinquenta e sete características foram extraídas dos documentos para realizar os experimentos dessa pesquisa. Destas, duas foram constantemente selecionadas pelos algoritmos de seleção de características. Foram elas:

\begin{itemize}
\item Diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo
\item Diferença entre a soma positiva e negativa dos unigrams e bigrams
\end{itemize}

Essas características englobam unigrams e bigrams formados por advérbios e adjetivos. Esses resultados corroboram quase que completamente os n-grams propostos por \cite{turney2002thumbs}, formados em sua maioria por advérbios e adjetivos; reiteram também a importância central dos adjetivos na mineração e classificação de opiniões, como apontado por \cite{voll2007not}; além de reforçar o proposto por \cite{benamara2007sentiment} que advérbios tema significativa influência como modificadores de intensidade dos adjetivos.

Também comparamos a configuração final do nosso classificador com um método clássico de aprendizado de máquina muito utilizado na tarefa de mineração de opinião, o \textit{Support Vector Machine} (SVM), e que geralmente produz bons resultados, como ser visto em \cite{moraes2012document}, \cite{pang2002thumbs}, \cite{pang2004sentimental} e \cite{wilson2004just}. 

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& Wang-Mendel 2 conjuntos fuzzy						& SVM \\ \hline
    TNR 				& 71.2\% $\pm$ 4.33\%            								& 72.9\% $\pm$ 5.80\%    \\
    TPR    			& 70.6\% $\pm$ 3.35\%     									& 68.6\% $\pm$ 7.04\%   \\
    acuracia  		& 70.9\% $\pm$ 3.07\%             							& 70.75\% $\pm$ 3.70\%    \\
    \end{tabular}
    \caption{Comparação entre os resultados do método de Wang-Mendel e SVM na base de filmes}
	\label{table:movies_svm}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -0.5606. The p-value is 0.57548. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 22. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         				& Wang-Mendel 2 conjuntos fuzzy 							& SVM \\ \hline
    TNR 			     	& 77.2\% $\pm$ 3.54\%            									& 75.5\% $\pm$ 3.20\%    \\
    TPR    			   	& 64.4\% $\pm$ 3.46\%   											& 65.8\% $\pm$ 4.64\%   \\
    acuracia  		   & 70.8\% $\pm$ 3.27\%       										& 70.65\% $\pm$ 2.99\%    \\
    \end{tabular}
    \caption{Comparação entre os resultados do método de Wang-Mendel e SVM na base da Amazon}
	\label{table:amazon_svm}
\end{table}

%Result 1 - Z-value
%
%The Z-value is -1.2232. The p-value is 0.22246. The result is not significant at p≤ 0.01.
%
%Result 2 - W-value
%
%The W-value is 15.5. The critical value of W for N = 10 at p≤ 0.01 is 3. Therefore, the result is not significant at p≤ 0.01.

Nossos resultados mostram que o classificador construído nesse trabalho equivale aos resultados do SVM, pois em ambas as bases as diferenças dos resultados não são significativas para $p <= 0.01$. Contudo, nosso classificador possui regras legíveis para seres humanos, é independente de domínio e não precisa de nova rodada de treino para diferentes bases, diferentemente do SVM.

\end{document}