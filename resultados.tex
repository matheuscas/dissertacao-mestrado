\xchapter{Resultados obtidos}{}

Nessa seção são descritos e discutidos os experimentos realizados e os resultados obtidos desses experimentos. O objetivo principal não é comparar qual cenário obtém melhor \textit{accuracy} ou \textit{F1}, mas também discutir em quais contextos os classificadores produzem melhores ou piores resultados.

\section{Datasets}

Nós executamos nossos experimentos em três bases de dados. Duas já foram mencionadas anteriormente, que são a base de dados de filmes \cite{pang2004sentimental} e a de diferentes categorias da Amazon \cite{wang2011latent}. Ambas contém 2000 documentos que foram previamente classificadas pelo sentimento geral das opiniões como sendo positivos ou negativos. Além disso, estas bases são ditas equilibradas, pois tem a mesma quantidade de documentos positivos e negativos. 

Para a base da Amazon, a referência para definir o sentimento geral dos documentos foi a quantidade de estrelas recebidas pelo usuário: mais de três estrelas o documentos era considerado positivo e menos que isso, negativo. Os documentos com exatamente 3 estrelas foram removidos de nossa análise por não serem claros quanto ao sentimento geral expresso para serem usados como referência. Além disso, a base da Amazon, originalmente, possui 20000 documentos. Contudo ela está  desbalanceada, onde mais 75\% dos documentos são positivos e o restante negativos. Assim, sorteamos, aleatoriamente, 1000 documentos positivos e 1000 documentos negativos para equiparar ao mesmo volume de dados da base de filmes. Sobre a base de filmes, como já dissemos anteriormente, esta já tinha sido pré classificada por seus autores \cite{pang2004sentimental}.

A terceira base, um conjunto de documentos retirados do site Epinions por \cite{taboada2011lexicon}, é composta por 400 documentos de 8 categorias diferentes: livros, carros, computadores, panelas, hotéis, filmes, música e telefones. Cada categoria possui 50 documentos equilibrados, sendo 25 positivos e 25 negativos, classificados préviamente pelo autor da base. Essa base foi utilizada para verificarmos a efetividade de regras criadas em uma base de dados e usadas em outras, nesse caso, a base da Epinions. 

\section{Design dos experimentos}

Nós focamos em comparar os métodos de classificação MGRF e MCRF, variando as configurações em diferentes etapas do processo de mineração de opinião, comparando as medidas de \textit{accuracy} e \textit{F1}. Nós também avaliamos a influência dos algoritmos de seleção de características, os sistemas de inferência fuzzy em si, a quantidade usada de conjuntos fuzzy, a eficiência das regras geradas num domínio e usadas em outro e as características mais selecionadas entre as bases utilizadas. 

Para cada base de dados, o processo é idêntico para as etapas de pré-processamento, transformação e extração de características. A partir da seleção de características, as etapas seguintes foram executadas com validação cruzada de 10 dobras, utilizando somente as treinamento. Por exemplo, a dobra 1 não é usada para a seleção de características e é usada como teste nas etapas seguintes de classificação e avaliação. Mas as dobras restantes são usadas na seleção de características e na construção base de regras fuzzy para aquela dobra 1. O mesmo processo é repetido para cada dobra e nossos resultados, para todas as métricas usadas, são a média das dobras de teste. Conseqüentemente, todos os tipos de n-grams combinados com todas as técnicas de transformação descritas nesse trabalho passam pela seleção de características para encontrar quais delas são mais apropriadas para representar os documentos. 

\subsection{Avaliação dos algoritmos de seleção de características}

Para avaliar os algoritmos de seleção de características, CFS e C45, foi definido o seguinte cenário: 3 conjuntos fuzzy para as variáveis de entrada e o uso do MCRF para ambos os datasets, filmes e a base mista da Amazon. Assim, deixando os demais parâmetros inalterados, nós podemos avaliar o desempenho dos algoritmos de seleção de características. Além de avaliar \textit{accuracy}, \textit{recall}, \textit{precision} e \textit{F1}, foi avaliado também a quantidade média de características selecionadas para cada algoritmo de seleção. A tabela (\ref{table:movies}) e tabela (\ref{table:amazon}) mostram, respectivamente, os resultados para este cenário nas bases de filmes e da Amazon. 

\begin{table}[!h]
    \begin{tabular}{lll}
    Movies         				 & CFS                                 	 	 & c4.5                                  \\ \hline
    Precision                   & 53.65\% $\pm$ 6.09\% 			 & 73.09\% $\pm$ 21.24\% \\
    Recall                        & 64.2\% $\pm$ 30.55\% 		 & 52.3\% $\pm$ 44.78\% \\
    Accuracy                   & 52.25\% $\pm$ 4.92\% 			 & 54.2\% $\pm$ 1.76\% \\
    F1                  			 & 53.45\% $\pm$ 14.88\% 	     & 41.04\% $\pm$ 3.83\% \\
    Features selected      & 4.7 $\pm$ 1.1            			 & 1                                     \\
    \end{tabular}
    \caption{Resultados da base de filmes}
	\label{table:movies}
\end{table}

\begin{table}[!h]
    \begin{tabular}{lll}
    Movies         					& CFS                          		& c4.5                                  \\ \hline
    Precision                     & 61.99\% $\pm$ 9.01\% 	& 66.01\% $\pm$ 22.25\%  \\
    Recall                          & 77.5\% $\pm$ 13.9\% 		& 74.5\% $\pm$ 38.82\% \\
    Accuracy                     & 64.4\% $\pm$ 8.12\% 		& 54.25\% $\pm$ 2.82\% \\
    F1                                & 68.17\% $\pm$ 8.65\% 	& 55.42\% $\pm$ 19.43\% \\
    Features selected 		& 5.3 $\pm$ 0.64               & 1 $\pm$                                  \\
    \end{tabular}
    \caption{Resultados da base da Amazon}
	\label{table:amazon}
\end{table}

Como pode ser visto, a seleção de características com c4.5 usando o MCRF e três conjuntos fuzzy na entrada produziu melhor \textit{precision} e \textit{accuracy}, esta última mesmo que próxima, na base de filmes, usando menos da metade de características usadas no algoritmo CFS. Contudo, o inverso ocorreu na base da Amazon, onde o CFS com o MCRF produziu melhor resultado que o c4.5, mas utilizando ainda mais características para a geração das regras. Isso resulta em regras com 5 antecedentes, em média, menos legíveis e compreensíveis para um ser humano. Assim, já que o algoritmo c4.5 somente precisou de 2 características, produzindo regras menos complexas e mais claras, para produzir resultados melhores (considerando \textit{accuracy)}, no caso de filmes, e próximos, no caso da Amazon, foi decidido em manter o c4.5 para os próximos cenários de avaliação. 

Um outro comportamento, agora comum para ambas as bases foi o baixo balanço (\textit{F1}) entre a classificação dos documentos positivos e negativos. Foi possível perceber que a cada dobra da validação cruzada, documentos positivos eram classificados mais corretamente em detrimento aos negativos e vice-versa.
A tabela (\ref{table:amazon_folds}) mostra as matrizes de confusão de cada dobra para os resultados produzidos na base da Amazon. 

\begin{table}[!h]
    \begin{tabular}{lll}
    a         					& b                          		& classificado como                                  \\ \hline
	Dobra 0 \\    
    6 (TP)    				&94 (FN)      				& b = negative (100) \\
    0 (FP)    				&100 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 1    \\
    5 (TP)    				&95 (FN)      				& b = negative (100) \\
    0 (FP)    				&100 (TN)      				& b = negative (100) \\
	&&\\ 
	Dobra 2    \\
    96 (TP)    				&4 (FN)      				& b = negative (100) \\
    87 (FP)    				&13 (TN)      				& b = negative (100) \\
	&&\\
    Dobra 3    \\
    98 (TP)    				&2 (FN)      				& b = negative (100) \\
    94 (FP)    				&6 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 4    \\
    99 (TP)    				&1 (FN)      				& b = negative (100) \\
    88 (FP)    				&12 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 5    \\
    4 (TP)    				&96 (FN)      				& b = negative (100) \\
    1 (FP)    				&99 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 6    \\
    9 (TP)    				&91 (FN)      				& b = negative (100) \\
    0 (FP)    				&100 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 7    \\
    97 (TP)    				&3 (FN)      				& b = negative (100) \\
    83 (FP)    				&17 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 8    \\
    14 (TP)    				&86 (FN)      				& b = negative (100) \\
    2 (FP)    				&98 (TN)      				& b = negative (100) \\
	&&\\
	Dobra 9    \\
    95 (TP)    				&5 (FN)      				& b = negative (100) \\
    84 (FP)    				&16 (TN)      				& b = negative (100) \\
	&&\\
    \end{tabular}
    \caption{Resultados das dobras da base da Amazon}
	\label{table:amazon_folds}
\end{table}

É possível perceber que há alternância entre as dobras para as extremidades da classificação dos documentos: ou são todos (ou quase) positivos ou quase todos negativos. E ainda que um novo embaralhamento dos dados seja feito e uma nova seleção de características, o efeito se repete e os resultados pouco melhoram e pioram bastante em alguns casos. 

\subsubsection{Avaliação do impacto da altura da árvore de decisão do algoritmo de seleção de características do c4.5}

É importante ressaltar que os resultados anteriores, para o c4.5, foram obtidos com o algoritmo otimizado, utilizando a ferramenta Weka [CITE], para que a árvore tivesse altura 1, para fins de simplificação e aumento da generalização do algoritmo. Dessa forma, decidimos avaliar o quanto o aumento da altura da árvore de decisão do algoritmo de seleção de características do c4.5 influenciaria na classificação dos documentos. Definimos que o limite da altura da árvore de decisão fosse 3 para não aumentar demais a complexidade das regras que serão geradas. A tabela (\ref{table:movies_h3}) e tabela (\ref{table:amazon_h3}) mostram, respectivamente, os resultados para este cenário nas bases de filmes e da Amazon.

 \begin{table}[!h]
    \begin{tabular}{lll}
    Movies         				 & c4.5 - Altura 3                                 	 	 & c4.5 - Altura 1                               \\ \hline
    Precision                   & 71.77\% $\pm$ 19.87\% 			 & 73.09\% $\pm$ 21.24\% \\
    Recall                        & 53.4\% $\pm$ 44.50\% 		 & 52.3\% $\pm$ 44.78\% \\
    Accuracy                   & 54.5\% $\pm$ 1.76\% 			 & 54.2\% $\pm$ 1.76\% \\
    F1                  			 & 42.28\% $\pm$ 26.63\% 	     & 41.04\% $\pm$ 3.83\% \\
    Features selected      & 1.1 $\pm$ 0.3            			 & 1                                     \\
    \end{tabular}
    \caption{Resultados da base de filmes}
	\label{table:movies_h3}
\end{table}

\begin{table}[!h]
    \begin{tabular}{lll}
    Movies         					& c4.5 - Altura 3                          		& c4.5 - Altura 1                              \\ \hline
    Precision                     & 81.22\% $\pm$ 18.36\% 		& 66.01\% $\pm$ 22.25\%  \\
    Recall                          & 47.1\% $\pm$ 34.22\% 		& 74.5\% $\pm$ 38.82\% \\
    Accuracy                     & 60.4\% $\pm$ 5.72\% 			& 54.25\% $\pm$ 2.82\% \\
    F1                                & 47.62\% $\pm$ 19.17\% 	& 55.42\% $\pm$ 19.43\% \\
    Features selected 		& 1.9 $\pm$ 0.7               		& 1 $\pm$                                  \\
    \end{tabular}
    \caption{Resultados da base da Amazon}
	\label{table:amazon_h3}
\end{table}

Os resultados mostram comportamentos diferentes entre as bases, mas uma tendência já vista nos resultados anteriores. A base da Amazon precisa de mais características para poder classificar melhor os documentos. Esses resultados sugerem que para esse tipo de conjunto de dados diversificado (lembrando que a base da Amazon é composta de filmes, hotéis, GPS, telefones, dentre outros), faz-se necessário mais características para descrever melhor os documentos para que possam ser identificados corretamente pelo classificador. Por outro lado, os resultados pouco se alteraram na base de filmes, evidenciando que pouco será eficaz o acréscimo de mais características para descrever os documentos. Nesse caso, para a base de filmes, é necessário encontrar as características mais aptas a descreverem melhor os documentos. 

\subsection{Avaliação dos sistemas de inferência}

Nessa subseção é avaliado o desempenho dos sistemas de inferência escolhidos, o Método Geral do Raciocínio Fuzzy (MGRF) e o Método Clássico do Raciocínio Fuzzy (MCRF). Da mesma maneira que foi feita na seção anterior, nós fixamos os demais parâmetros do experimento para melhor avaliar os sistemas de inferência, mantendo o algoritmo de seleção de característica c4.5 (com altura 1, para continuar buscando a geração de regras claras e de fácil leitura para humanos) e 3 conjuntos fuzzy nas variáveis de entrada. A tabela (\ref{table:movies2}) e tabela (\ref{table:amazon2}) mostram, respectivamente, os resultados para este cenário nas bases de filmes e da Amazon.

\begin{table}[!h]
    \begin{tabular}{lll}
 	~         			& CFRM 								& GFRM \\ \hline
    Precision 		& 68.35\% $\pm$ 19.96\%   & 67.55\% $\pm$ 14.61\%    \\
    Recall    		& 61.7\% $\pm$ 43.93\%   & 64.6\% $\pm$ 37.08\%   \\
    Accuracy  		& 54.4\% $\pm$ 1.72\%    	& 59.2\% $\pm$ 1.83\%    \\
    F1  					& 46.81\% $\pm$ 26.74\% & 54.69\% $\pm$ 19.62\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base de filmes}
	\label{table:movies2}
\end{table}

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& CFRM 									& GFRM \\ \hline
    Precision 		& 66.01\% $\pm$ 22.25\%    	& 67.49\% $\pm$ 18.33\%    \\
    Recall    		& 74.5\% $\pm$ 38.82\%    	& 75.5\% $\pm$ 34.80\%    \\
    Accuracy  		& 54.25\% $\pm$ 2.82\%    		& 60.05\% $\pm$ 2.37\%   \\
    F1  					& 55.52\% $\pm$ 19.43\%   	& 60.48\% $\pm$ 16.63	\%   \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base da Amazon}
	\label{table:amazon2}
\end{table}

Os resultados mostram que Método Geral do Raciocínio Fuzzy (MGRF) aumenta o \textit{accuracy} sobre o MCRF, em ambas bases,  mantendo a seleção de características e a quantidade de conjuntos fuzzy inalterados. Ainda é possível observar que o equilíbrio na classificação (\textit{F1}) dos documentos também melhorou tanto na base de filmes quanto na da Amazon, usando o MGRF. \todo[inline]{com certeza isso não será verdade depois de fazer a comparação estatística. Mas como ainda não tem ela, eu deixei assim mesmo.} Assim, nessa tarefa de classificação de somente duas classes, positivo e negativo, os resultados mostraram que uma melhor abordagem é considerar todas as regras de uma classe, em vez de uma única com maior grau. Daí, o MGRF foi a nossa escolha para alcançar melhores resultados nesse trabalho e será o método de classificação usado nos próximos experimentos. 

\subsubsection{Avaliação de uso de pesos nas regras dos sistemas de inferência}

Em \cite{ishibuchi2001effect} foi mostrado que é possivel aumentar a performance da classificação de regras fuzzy IF-THEN aplicando pesos à elas, além do grau de compatibilidade das regras. No referido artigo, os autores descreveram o processo em que é possível melhorar o desempenho da classificação sem alterar os conjuntos fuzzy das variáveis de saída e de entrada. Baseando-se neste artigo, este trabalho calculou os pesos como se segue. Para cada regra da base de regras gerada, foi calculado o grau de compatibilidade com todos documentos do conjunto de teste. Se o documento fosse positivo, o grau de compatibilidade era acumulado em $\beta_{positivo}$; se o documento fosse negativo, o grau de compatibilidade era acumulado em $\beta_{negativo}$. Caso ambos os betas fosse iguais, não há peso a ser considerado, já que as regras tem igual influência sobre o conjunto de dados que elas foram geradas. De outra forma, o peso da regra era definido pela equação \ref{eq:pesos}.

\begin{equation}
P_j = |\beta_{positivo} - \beta_{negativo}| / (\beta_{positivo} + \beta_{negativo})
\label{eq:pesos}
\end{equation}

onde $P_j$ é o peso da regra, para $0 <= P_j <= 1$. 

Uma vez que todas as regras tiveram seus pesos calculados, estes são adicionados ao processo de classificação de ambos os métodos utilizados até aqui, o MGRF e o MCRF. O peso torna-se um fator multiplicador do grau de cada regra em cada método. Assim, o MCRF em vez de levar em consideração a regra com maior grau de compatibilidade com o documento de teste, vai, agora, levar em consideração a regra com maior resultado da multiplicação do grau de compatibilidade e do peso da regra. O mesmo acontece para o MGRF ao considerar o grau médio entre as classes positivo e negativo. A tabela (\ref{table:movies2_pesos}) e tabela (\ref{table:amazon2_pesos}) mostram, respectivamente, os resultados para o uso dos pesos nas bases de filmes e da Amazon usando os parâmetros até agora estabelecidos. 

\begin{table}[!h]
    \begin{tabular}{lll}
 	~         			& CFRM 								& GFRM \\ \hline
    Precision 		& 70.12\% $\pm$ 4.32\%   & 70.36\% $\pm$ 3.88\%    \\
    Recall    		& 70.3\% $\pm$ 11.73\%   & 69.7\% $\pm$ 9.81\%   \\
    Accuracy  		& 69.8\% $\pm$ 4.03\%    	& 70.05\% $\pm$ 4.00\%    \\
    F1  					& 69.52\% $\pm$ 6.00\% & 69.64\% $\pm$ 5.62\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base de filmes utilizando pesos nas regras}
	\label{table:movies2_pesos}
\end{table}

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         			& CFRM 									& GFRM \\ \hline
    Precision 		& 72.91\% $\pm$ 4.22\%    	& 73.80\% $\pm$ 3.89\%    \\
    Recall    		& 65.9\% $\pm$ 6.25\%    		& 64.9\% $\pm$ 5.50\%    \\
    Accuracy  		& 70.55\% $\pm$ 3.12\%    	& 70.85\% $\pm$ 3.09\%   \\
    F1  					& 69.00\% $\pm$ 3.88\%   		& 68.92\% $\pm$ 3.82	\%   \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base da Amazon utilizando pesos nas regras}
	\label{table:amazon2_pesos}
\end{table}

Os resultados corroboraram as conclusões de \cite{ishibuchi2001effect} que é possível melhorar o desempenho da classificação sem alterar os conjuntos fuzzy das variáveis de saída e de entrada apenas aplicando pesos às regras geradas. O aumento da performance e do equilíbrio da classificação usando ambos os métodos e nas duas bases é bastante significativo, como pôde ser visto nas tabelas (\ref{table:movies2_pesos}) e (\ref{table:amazon2_pesos}). Dessa forma, serão mantidos os pesos para os próximos experimentos. 

\subsection{Avaliação da quantidade de conjuntos fuzzy usados}

Através das últimas seções, foram mostrados resultados utilizando 3 conjuntos fuzzy para modelar nossas variáveis lingüísticas. Seguindo a nossa decisão de usar o c4.5 com altura máxima da árvore de decisão para 1 para reduzir a complexidade das regras geradas e torna-las mais legíveis para seres humanos, nós tentamos reduzir a quantidade de conjuntos fuzzy, usando somente os conjuntos "Baixo" e "Alto", para as variáveis de entrada. Esse experimento tem por fim verificar se há aumento da performance da classificação com regras mais simples e gerais. A tabela (\ref{table:movies2_pesos_2f}) e tabela (\ref{table:amazon2_pesos_2fs}) mostram, respectivamente, os resultados para o uso de somente dois conjuntos fuzzy nas variáveis de entrada nas bases de filmes e da Amazon.

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         		& 3 fuzzy sets 							& 2 fuzzy sets \\ \hline
    Precision 	& 70.36\% $\pm$ 3.88\%       & 71.11\% $\pm$ 3.58\%    \\
    Recall    	& 69.7\% $\pm$ 9.81\%    		& 70.6\% $\pm$ 3.35\%   \\
    Accuracy  	& 70.05\% $\pm$ 4.00\%    	& 70.9\% $\pm$ 3.07\%    \\
    F1  				69.64\% $\pm$ 5.62\%    		& 70.81\% $\pm$ 2.98\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base de filmes utilizando 2 conjuntos fuzzy na entrada}
	\label{table:movies2_pesos_2fs}
\end{table}

\begin{table}[!h]
    \begin{tabular}{lll}
    ~         		& 3 fuzzy sets 							& 2 fuzzy sets \\ \hline
    Precision 	& 73.80\% $\pm$ 3.89\%            & 73.87\% $\pm$ 3.93\%    \\
    Recall    	& 64.9\% $\pm$ 5.50\% 				& 64.4\% $\pm$ 3.46\%   \\
    Accuracy  	& 70.85\% $\pm$ 3.09\%         	& 70.8\% $\pm$ 3.27\%    \\
    F1  				& 68.92\% $\pm$ 3.82	\%    		& 68.79\% $\pm$ 3.52\%    \\
    \end{tabular}
    \caption{Resultados dos sistemas de inferência na base da Amazon utilizando 2 conjuntos fuzzy na entrada}
	\label{table:amazon2_pesos_2fs}
\end{table}

A tabela (\ref{table:movies2_pesos_2fs}) mostra que todos, mesmo em pequena escala, os indicadores do classificador tiveram uma melhora. Além disso, mesmo que também por uma diferença pequena, o melhor resultado geral da performance do classificador foi na base de filmes. Isso é especificamente interessante, pois críticas de filmes são comumente reportadas como o mais difícil tipo de documentos de serem classificados \cite{turney2002thumbs,pang2004sentimental,chaovalit2005movie,ohana2009sentiment}. 

%positive_to_negative_ratio_of_adjectives_sum_and_bigrams_with_adjectives
%positive_to_negative_ratio_of_unigrams_and_bigrams_sum
Em ambos conjuntos de dados somente duas características foram selecionadas pelo c4.5:
\begin{itemize}
\item Diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo
\item Diferença entre a soma positiva e negativa dos unigrams e bigrams
\end{itemize}

Na base de filmes as duas foram necessárias para atingir os resultados mostrados na tabela ((\ref{table:movies2_pesos_2fs})). Novamente remete ao fato de documentos de filmes sejam mais difíceis de serem classificados, precisem de mais características para caracterizar bem as críticas. Já na base da Amazon, somente a segunda característica foi utilizada para classificar os documentos. Embora o algoritmo tenha decidido que somente essa característica seja suficiente, não é difícil concluir que, sendo a base da Amazon bastante diversa (e que também inclui filmes), mais características podem ser necessárias para caracterizar melhor documentos tão variados.
Todavia, nós conseguimos classificar um pouco mais de 70\% dos documentos de filmes e da Amazon com poucas regras simples, legíveis para humanos, geradas pelo método de Wang-Mendel:

\begin{itemize}
\item IF a \textit{diferença entre a soma positiva e negativa dos unigrams e bigrams} is ALTO then POLARIDADE is POSITIVA
\item IF a \textit{diferença entre a soma positiva e negativa dos unigrams e bigrams} is BAIXO then POLARIDADE is NEGATIVA
\item IF a \textit{diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo} is ALTO then POLARIDADE is POSITIVA
\item IF a \textit{diferença entre a soma positiva e negativa dos adjetivos e dos bigrams formados por advérbio e adjetivo} is BAIXO then POLARIDADE is NEGATIVA
\end{itemize}

As quatro regras foram utilizadas na base de filmes e as duas primeiras regras na base da Amazon.

\subsection{Avaliação do uso de regras entre domínios}

Usar regras geradas em um domínio e usar para classificar em outro.

\subsection{Avaliação das características mais selecionadas entre domínios}

Discutir os motivos de tais features terem sido mais selecionadas em vez das outras

\section{Outros resultados}

Seguindo a reta do artigo
